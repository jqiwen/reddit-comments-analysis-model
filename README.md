### âœ… To Run the Project:
Open and run `model.py` from the project home directory.  
All results will be automatically saved under the `outputs/` folder.

### ğŸ“ Outputs Directory Overview

There are **3 main result files** saved under the `outputs/` folder:

- `data_annotation_with_ground_truth.xlsx` â€” Final annotated dataset with adjudicated ground truth labels.
- `ground_truth_label_distribution_pie.png` â€” Pie chart showing the distribution of ground truth labels.
- `baseline_results.txt` â€” Evaluation results from both baseline and trained models.

### ğŸ“ training_model Directory Overview

There are **3 Python files** under the `training_model/` directory:

#### ğŸ”¸ `data_analysis.py` â€” Annotation Analysis
Includes:
- **Cohen's Kappa**  
  â†’ Result will be printed in the terminal.
- **Ground Truth Adjudication**  
  â†’ Saved as `outputs/data_annotation_with_ground_truth.xlsx`.
- **Ground Truth Label Distribution (Pie Chart)**  
  â†’ Saved as `outputs/ground_truth_label_distribution_pie.png`.

#### ğŸ”¸ `baseline_model.py` â€” Simple Baseline Model
- Implements a **Random Baseline classifier**.
- Evaluation results are saved in:  
  â†’ `outputs/baseline_results.txt`

#### ğŸ”¸ `trained_model.py` â€” Trained Models
- Includes two trained models:
  - **Logistic Regression**
  - **Random Forest**
- Evaluation results are saved in:  
  â†’ `outputs/baseline_results.txt`

---

If needed, you can add a link at the end:
> ğŸ“ *Codabench Task Link:* [Igh]  
> ğŸ“ *Presentation Slides:* [hjh]
